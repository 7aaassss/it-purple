#from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline

#tokenizer = AutoTokenizer.from_pretrained("sambanovasystems/SambaLingo-Russian-Chat", use_fast=False)
#model = AutoModelForCausalLM.from_pretrained("sambanovasystems/SambaLingo-Russian-Chat", device_map="auto", torch_dtype="auto")
#pipe = pipeline("text-generation", model="ai-forever/mGPT")



